"""
SQLiteCache å•å…ƒæµ‹è¯•

è¦†ç›–èŒƒå›´ï¼š
- åŸºæœ¬ CRUD æ“ä½œ (get/set/delete/exists/clear)
- TTL è¿‡æœŸæœºåˆ¶
- æ‰¹é‡æ“ä½œ (get_many/set_many/delete_many)
- ç¼“å­˜é”®æ¨¡å¼åŒ¹é…
- MarketData åºåˆ—åŒ–/ååºåˆ—åŒ–
- é€šç”¨å¯¹è±¡ (pickle) åºåˆ—åŒ–
- å¸‚åœºæ•°æ®ä¸“ç”¨è¡¨ (save_market_data/get_market_data)
- æ•°æ®æŒä¹…åŒ–ï¼ˆé‡å»ºå®ä¾‹åæ•°æ®ä»å­˜åœ¨ï¼‰
- ç¼“å­˜å‘½ä¸­/æœªå‘½ä¸­æµç¨‹ï¼ˆæ¨¡æ‹Ÿ DataProviderï¼‰
- ç¼“å­˜ vs è¿œç«¯æ•°æ®æºæ€§èƒ½å¯¹æ¯”
- get_or_set ç¼“å­˜ç©¿é€ä¿æŠ¤
- è¿‡æœŸæ¸…ç† (cleanup_expired)
- ç»Ÿè®¡ä¿¡æ¯ (stats)
- å¹¶å‘è®¿é—®å®‰å…¨æ€§
- è¾¹ç•Œä¸å¼‚å¸¸åœºæ™¯
"""

import asyncio
import os
import pickle
import tempfile
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional
from unittest.mock import AsyncMock, patch

import pytest
from data.cache.base import CacheBackend
from data.cache.sqlite_cache import SQLiteCache
from data.models import OHLCV, MarketData
from data.providers import DataInterval, DataProvider

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def run_async(coro):
    """åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œåç¨‹"""
    return asyncio.run(coro)


def make_ohlcv(
    day: int = 1,
    month: int = 1,
    year: int = 2025,
    open_: float = 100.0,
    high: float = 110.0,
    low: float = 90.0,
    close: float = 105.0,
    volume: float = 1_000_000,
    adjusted_close: float = 105.0,
) -> OHLCV:
    """å¿«é€Ÿæ„å»º OHLCV å¯¹è±¡"""
    return OHLCV(
        timestamp=datetime(year, month, day),
        open=open_,
        high=high,
        low=low,
        close=close,
        volume=volume,
        adjusted_close=adjusted_close,
    )


def make_market_data(symbol: str = "AAPL", days: int = 30) -> MarketData:
    """æ„å»ºåŒ…å« N å¤©æ•°æ®çš„ MarketData"""
    data = []
    for i in range(days):
        base = 150.0 + i * 0.5
        data.append(
            OHLCV(
                timestamp=datetime(2025, 1, 1) + timedelta(days=i),
                open=base,
                high=base + 5.0,
                low=base - 3.0,
                close=base + 2.0,
                volume=1_000_000 + i * 10_000,
                adjusted_close=base + 2.0,
            )
        )
    return MarketData(
        symbol=symbol,
        data=data,
        metadata={"source": "test", "interval": "1d"},
    )


class FakeRemoteProvider(DataProvider):
    """
    æ¨¡æ‹Ÿè¿œç«¯æ•°æ®æº

    æ¯æ¬¡ get_historical_data äººä¸ºå¼•å…¥å»¶è¿Ÿä»¥æ¨¡æ‹Ÿç½‘ç»œ I/Oï¼Œ
    å¹¶è®°å½•å®é™…è°ƒç”¨æ¬¡æ•°ï¼Œç”¨äºéªŒè¯ç¼“å­˜æ˜¯å¦ç”Ÿæ•ˆã€‚
    """

    def __init__(self, cache_backend=None, latency: float = 0.05):
        super().__init__(cache_backend)
        self.latency = latency
        self.api_call_count = 0

    @property
    def name(self) -> str:
        return "fake_remote"

    @property
    def supported_intervals(self):
        return [DataInterval.DAILY]

    async def get_historical_data(
        self,
        symbol: str,
        start_date: datetime,
        end_date: Optional[datetime] = None,
        interval: DataInterval = DataInterval.DAILY,
    ) -> MarketData:
        end_date = end_date or datetime.now()
        cache_key = self._generate_cache_key(symbol, start_date, end_date, interval)

        # å…ˆæŸ¥ç¼“å­˜
        if self.cache:
            cached = await self.cache.get(cache_key)
            if cached is not None:
                return cached

        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await asyncio.sleep(self.latency)
        self.api_call_count += 1

        market_data = make_market_data(symbol, days=30)

        # å†™ç¼“å­˜
        if self.cache and not market_data.is_empty:
            await self.cache.set(cache_key, market_data)

        return market_data

    async def get_latest_price(self, symbol: str) -> Optional[float]:
        return 150.0

    async def get_quote(self, symbol):
        return {"price": 150.0}


# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------


@pytest.fixture
def tmp_db(tmp_path):
    """è¿”å›ä¸´æ—¶æ•°æ®åº“è·¯å¾„"""
    return str(tmp_path / "test_cache.db")


@pytest.fixture
def cache(tmp_db):
    """åˆ›å»ºå…¨æ–°çš„ SQLiteCache å®ä¾‹"""
    return SQLiteCache(db_path=tmp_db)


@pytest.fixture
def market_data():
    """30 å¤© AAPL æµ‹è¯•æ•°æ®"""
    return make_market_data("AAPL", days=30)


# =========================================================================
# 1. åŸºæœ¬ CRUD æ“ä½œ
# =========================================================================


class TestBasicCRUD:
    """åŸºç¡€è¯»/å†™/åˆ /å­˜åœ¨æ€§/æ¸…ç©ºæ“ä½œ"""

    def test_set_and_get(self, cache):
        """å†™å…¥ååº”èƒ½è¯»å–åˆ°ç›¸åŒçš„å€¼"""

        async def _test():
            await cache.set("key1", "value1")
            result = await cache.get("key1")
            assert result == "value1"

        run_async(_test())

    def test_get_nonexistent_key(self, cache):
        """è¯»å–ä¸å­˜åœ¨çš„é”®åº”è¿”å› None"""

        async def _test():
            result = await cache.get("nonexistent")
            assert result is None

        run_async(_test())

    def test_set_overwrite(self, cache):
        """å¯¹åŒä¸€ä¸ªé”®å¤šæ¬¡å†™å…¥ï¼Œæœ€åä¸€æ¬¡åº”è¦†ç›–ä¹‹å‰çš„å€¼"""

        async def _test():
            await cache.set("key1", "old")
            await cache.set("key1", "new")
            result = await cache.get("key1")
            assert result == "new"

        run_async(_test())

    def test_delete_existing_key(self, cache):
        """åˆ é™¤å­˜åœ¨çš„é”®åº”è¿”å› Trueï¼Œä¹‹å get è¿”å› None"""

        async def _test():
            await cache.set("key1", "value1")
            deleted = await cache.delete("key1")
            assert deleted is True
            assert await cache.get("key1") is None

        run_async(_test())

    def test_delete_nonexistent_key(self, cache):
        """åˆ é™¤ä¸å­˜åœ¨çš„é”®åº”è¿”å› False"""

        async def _test():
            deleted = await cache.delete("nonexistent")
            assert deleted is False

        run_async(_test())

    def test_exists(self, cache):
        """exists æ­£ç¡®åæ˜ é”®çš„å­˜åœ¨çŠ¶æ€"""

        async def _test():
            assert await cache.exists("key1") is False
            await cache.set("key1", "val")
            assert await cache.exists("key1") is True

        run_async(_test())

    def test_clear(self, cache):
        """clear æ¸…ç©ºå…¨éƒ¨ç¼“å­˜å¹¶è¿”å›åˆ é™¤çš„æ¡ç›®æ•°"""

        async def _test():
            await cache.set("a", 1)
            await cache.set("b", 2)
            await cache.set("c", 3)
            count = await cache.clear()
            assert count == 3
            assert await cache.get("a") is None
            assert await cache.get("b") is None
            assert await cache.get("c") is None

        run_async(_test())

    def test_clear_empty_cache(self, cache):
        """æ¸…ç©ºç©ºç¼“å­˜åº”è¿”å› 0"""

        async def _test():
            count = await cache.clear()
            assert count == 0

        run_async(_test())


# =========================================================================
# 2. æ•°æ®ç±»å‹åºåˆ—åŒ–
# =========================================================================


class TestSerialization:
    """éªŒè¯ä¸åŒæ•°æ®ç±»å‹çš„åºåˆ—åŒ–ä¸ååºåˆ—åŒ–"""

    def test_string(self, cache):
        async def _test():
            await cache.set("s", "hello world")
            assert await cache.get("s") == "hello world"

        run_async(_test())

    def test_integer(self, cache):
        async def _test():
            await cache.set("i", 42)
            assert await cache.get("i") == 42

        run_async(_test())

    def test_float(self, cache):
        async def _test():
            await cache.set("f", 3.14159)
            result = await cache.get("f")
            assert abs(result - 3.14159) < 1e-10

        run_async(_test())

    def test_dict(self, cache):
        async def _test():
            data = {"nested": {"key": [1, 2, 3]}, "flag": True}
            await cache.set("d", data)
            assert await cache.get("d") == data

        run_async(_test())

    def test_list(self, cache):
        async def _test():
            data = [1, "two", 3.0, None, True]
            await cache.set("l", data)
            assert await cache.get("l") == data

        run_async(_test())

    def test_bytes(self, cache):
        async def _test():
            data = b"\x00\x01\x02\xff"
            await cache.set("b", data)
            assert await cache.get("b") == data

        run_async(_test())

    def test_market_data_serialization(self, cache, market_data):
        """MarketData èµ° JSON åºåˆ—åŒ–è·¯å¾„ï¼Œååºåˆ—åŒ–åæ•°æ®å®Œå…¨ä¸€è‡´"""

        async def _test():
            await cache.set("md", market_data)
            restored = await cache.get("md")

            assert isinstance(restored, MarketData)
            assert restored.symbol == market_data.symbol
            assert len(restored) == len(market_data)
            assert restored.metadata == market_data.metadata

            # é€æ¡æ¯”è¾ƒ OHLCV
            for orig, rest in zip(market_data.data, restored.data):
                assert orig.timestamp == rest.timestamp
                assert orig.open == rest.open
                assert orig.high == rest.high
                assert orig.low == rest.low
                assert orig.close == rest.close
                assert orig.volume == rest.volume
                assert orig.adjusted_close == rest.adjusted_close

        run_async(_test())

    def test_empty_market_data(self, cache):
        """ç©º MarketData çš„åºåˆ—åŒ–/ååºåˆ—åŒ–"""

        async def _test():
            empty = MarketData(symbol="EMPTY", data=[], metadata={})
            await cache.set("empty_md", empty)
            restored = await cache.get("empty_md")
            assert isinstance(restored, MarketData)
            assert restored.symbol == "EMPTY"
            assert restored.is_empty

        run_async(_test())

    def test_serialize_data_type_tag(self, cache, market_data):
        """éªŒè¯ MarketData å’Œé MarketData ä½¿ç”¨ä¸åŒçš„ data_type æ ‡ç­¾"""

        async def _test():
            # MarketData â†’ data_type = "market_data"
            blob_md, dtype_md = cache._serialize(market_data)
            assert dtype_md == "market_data"

            # æ™®é€šå¯¹è±¡ â†’ data_type = "pickle"
            blob_gen, dtype_gen = cache._serialize({"key": "value"})
            assert dtype_gen == "pickle"

        run_async(_test())


# =========================================================================
# 3. TTL è¿‡æœŸæœºåˆ¶
# =========================================================================


class TestTTL:
    """éªŒè¯ç¼“å­˜è¿‡æœŸè¡Œä¸º"""

    def test_ttl_not_expired(self, cache):
        """TTL æœªåˆ°æœŸæ—¶åº”æ­£å¸¸è¿”å›"""

        async def _test():
            await cache.set("k", "v", ttl=timedelta(seconds=60))
            result = await cache.get("k")
            assert result == "v"

        run_async(_test())

    def test_ttl_expired(self, cache):
        """TTL è¿‡æœŸå get åº”è¿”å› None"""

        async def _test():
            await cache.set("k", "v", ttl=timedelta(milliseconds=50))
            await asyncio.sleep(0.1)  # ç­‰å¾…è¿‡æœŸ
            result = await cache.get("k")
            assert result is None

        run_async(_test())

    def test_ttl_auto_delete_on_get(self, cache):
        """è¿‡æœŸæ¡ç›®åœ¨ get æ—¶è¢«è‡ªåŠ¨åˆ é™¤"""

        async def _test():
            await cache.set("k", "v", ttl=timedelta(milliseconds=50))
            await asyncio.sleep(0.1)

            # get è§¦å‘åˆ é™¤
            assert await cache.get("k") is None

            # ç¡®è®¤ç¡®å®ä»æ•°æ®åº“ä¸­ç§»é™¤
            keys = await cache.keys("k")
            assert "k" not in keys

        run_async(_test())

    def test_no_ttl_never_expires(self, cache):
        """ä¸è®¾ TTL çš„æ¡ç›®ä¸ä¼šè¿‡æœŸ"""

        async def _test():
            await cache.set("k", "v")  # æ—  TTL
            await asyncio.sleep(0.1)
            assert await cache.get("k") == "v"

        run_async(_test())

    def test_default_ttl(self, tmp_db):
        """é€šè¿‡ default_ttl å‚æ•°è®¾ç½®å…¨å±€è¿‡æœŸæ—¶é—´"""

        async def _test():
            c = SQLiteCache(db_path=tmp_db, default_ttl=timedelta(milliseconds=50))
            await c.set("k", "v")  # æœªæ˜¾å¼æŒ‡å®š ttlï¼Œä½¿ç”¨ default_ttl
            assert await c.get("k") == "v"

            await asyncio.sleep(0.1)
            assert await c.get("k") is None

        run_async(_test())

    def test_explicit_ttl_overrides_default(self, tmp_db):
        """æ˜¾å¼ä¼ å…¥ ttl åº”è¦†ç›– default_ttl"""

        async def _test():
            c = SQLiteCache(db_path=tmp_db, default_ttl=timedelta(milliseconds=50))
            # æ˜¾å¼è®¾ç½®è¾ƒé•¿çš„ TTL
            await c.set("k", "v", ttl=timedelta(seconds=60))
            await asyncio.sleep(0.1)
            assert await c.get("k") == "v"  # ä»ç„¶æœ‰æ•ˆ

        run_async(_test())

    def test_cleanup_expired(self, cache):
        """cleanup_expired æ‰¹é‡æ¸…ç†è¿‡æœŸæ¡ç›®"""

        async def _test():
            # å†™å…¥ 5 æ¡å³å°†è¿‡æœŸçš„ + 2 æ¡æ°¸ä¸è¿‡æœŸçš„
            for i in range(5):
                await cache.set(f"exp_{i}", i, ttl=timedelta(milliseconds=50))
            await cache.set("perm_a", "a")
            await cache.set("perm_b", "b")

            await asyncio.sleep(0.1)

            cleaned = await cache.cleanup_expired()
            assert cleaned == 5

            # æ°¸ä¸è¿‡æœŸçš„ä»ç„¶å­˜åœ¨
            assert await cache.get("perm_a") == "a"
            assert await cache.get("perm_b") == "b"

        run_async(_test())


# =========================================================================
# 4. æ‰¹é‡æ“ä½œ
# =========================================================================


class TestBatchOperations:
    """æ‰¹é‡è¯»å†™åˆ """

    def test_set_many_and_get_many(self, cache):
        async def _test():
            mapping = {"k1": "v1", "k2": "v2", "k3": "v3"}
            count = await cache.set_many(mapping)
            assert count == 3

            result = await cache.get_many(["k1", "k2", "k3", "missing"])
            assert result == {"k1": "v1", "k2": "v2", "k3": "v3"}

        run_async(_test())

    def test_delete_many(self, cache):
        async def _test():
            await cache.set_many({"a": 1, "b": 2, "c": 3})
            deleted = await cache.delete_many(["a", "c", "nonexistent"])
            assert deleted == 2  # a å’Œ c æˆåŠŸåˆ é™¤
            assert await cache.get("b") == 2

        run_async(_test())


# =========================================================================
# 5. ç¼“å­˜é”®æ¨¡å¼åŒ¹é…
# =========================================================================


class TestKeyPatterns:
    """keys() é€šé…ç¬¦åŒ¹é…"""

    def test_wildcard_all(self, cache):
        async def _test():
            await cache.set_many({"a:1": 1, "a:2": 2, "b:1": 3})
            all_keys = await cache.keys("*")
            assert set(all_keys) == {"a:1", "a:2", "b:1"}

        run_async(_test())

    def test_wildcard_prefix(self, cache):
        async def _test():
            await cache.set_many({"a:1": 1, "a:2": 2, "b:1": 3})
            keys = await cache.keys("a:*")
            assert set(keys) == {"a:1", "a:2"}

        run_async(_test())

    def test_wildcard_single_char(self, cache):
        async def _test():
            await cache.set_many({"abc": 1, "adc": 2, "aec": 3, "abcd": 4})
            keys = await cache.keys("a?c")
            assert set(keys) == {"abc", "adc", "aec"}

        run_async(_test())

    def test_no_match(self, cache):
        async def _test():
            await cache.set("foo", 1)
            keys = await cache.keys("bar*")
            assert keys == []

        run_async(_test())


# =========================================================================
# 6. å¸‚åœºæ•°æ®ä¸“ç”¨è¡¨
# =========================================================================


class TestMarketDataTable:
    """save_market_data / get_market_data ä¸“ç”¨è¡¨æ“ä½œ"""

    def test_save_and_retrieve(self, cache, market_data):
        """ä¿å­˜åæŒ‰ symbol + interval æ£€ç´¢"""

        async def _test():
            saved = await cache.save_market_data("AAPL", "1d", market_data)
            assert saved == len(market_data)

            retrieved = await cache.get_market_data("AAPL", "1d")
            assert retrieved is not None
            assert len(retrieved) == len(market_data)
            assert retrieved.symbol == "AAPL"
            assert retrieved.metadata.get("source") == "cache"

        run_async(_test())

    def test_retrieve_with_date_range(self, cache, market_data):
        """æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤"""

        async def _test():
            await cache.save_market_data("AAPL", "1d", market_data)

            start = datetime(2025, 1, 10)
            end = datetime(2025, 1, 20)
            retrieved = await cache.get_market_data("AAPL", "1d", start, end)

            assert retrieved is not None
            for ohlcv in retrieved.data:
                assert start <= ohlcv.timestamp <= end

        run_async(_test())

    def test_retrieve_nonexistent_symbol(self, cache):
        """æŸ¥è¯¢ä¸å­˜åœ¨çš„ symbol åº”è¿”å› None"""

        async def _test():
            result = await cache.get_market_data("ZZZZ", "1d")
            assert result is None

        run_async(_test())

    def test_save_empty_market_data(self, cache):
        """ä¿å­˜ç©º MarketData åº”è¿”å› 0"""

        async def _test():
            empty = MarketData(symbol="EMPTY")
            saved = await cache.save_market_data("EMPTY", "1d", empty)
            assert saved == 0

        run_async(_test())

    def test_upsert_on_conflict(self, cache, market_data):
        """é‡å¤å†™å…¥åŒä¸€ (symbol, interval, timestamp) åº”æ›´æ–°è€ŒéæŠ¥é”™"""

        async def _test():
            await cache.save_market_data("AAPL", "1d", market_data)
            # å†æ¬¡å†™å…¥ç›¸åŒæ•°æ®ä¸åº”æŠ›å¼‚å¸¸
            saved = await cache.save_market_data("AAPL", "1d", market_data)
            assert saved == len(market_data)

            # æ•°æ®æ¡æ•°ä¸åº”ç¿»å€
            retrieved = await cache.get_market_data("AAPL", "1d")
            assert len(retrieved) == len(market_data)

        run_async(_test())

    def test_multiple_symbols(self, cache):
        """åŒä¸€å¼ è¡¨å­˜å‚¨å¤šä¸ª symbol çš„æ•°æ®ï¼Œäº’ä¸å¹²æ‰°"""

        async def _test():
            aapl = make_market_data("AAPL", days=10)
            msft = make_market_data("MSFT", days=20)

            await cache.save_market_data("AAPL", "1d", aapl)
            await cache.save_market_data("MSFT", "1d", msft)

            r_aapl = await cache.get_market_data("AAPL", "1d")
            r_msft = await cache.get_market_data("MSFT", "1d")

            assert len(r_aapl) == 10
            assert len(r_msft) == 20

        run_async(_test())

    def test_multiple_intervals(self, cache):
        """åŒä¸€ symbol ä¸åŒ interval çš„æ•°æ®äº’ä¸å¹²æ‰°"""

        async def _test():
            daily = make_market_data("AAPL", days=30)
            weekly = make_market_data("AAPL", days=10)

            await cache.save_market_data("AAPL", "1d", daily)
            await cache.save_market_data("AAPL", "1w", weekly)

            r_daily = await cache.get_market_data("AAPL", "1d")
            r_weekly = await cache.get_market_data("AAPL", "1w")

            assert len(r_daily) == 30
            assert len(r_weekly) == 10

        run_async(_test())

    def test_ohlcv_values_preserved(self, cache):
        """é€å­—æ®µéªŒè¯ä¸“ç”¨è¡¨å†™å…¥çš„ OHLCV ç²¾åº¦"""

        async def _test():
            ohlcv = make_ohlcv(
                day=15,
                open_=123.456,
                high=130.789,
                low=118.123,
                close=127.654,
                volume=9_876_543,
                adjusted_close=127.654,
            )
            md = MarketData(symbol="TSLA", data=[ohlcv])
            await cache.save_market_data("TSLA", "1d", md)

            retrieved = await cache.get_market_data("TSLA", "1d")
            r = retrieved.data[0]
            assert abs(r.open - 123.456) < 1e-6
            assert abs(r.high - 130.789) < 1e-6
            assert abs(r.low - 118.123) < 1e-6
            assert abs(r.close - 127.654) < 1e-6
            assert abs(r.volume - 9_876_543) < 1e-6
            assert abs(r.adjusted_close - 127.654) < 1e-6

        run_async(_test())


# =========================================================================
# 7. æ•°æ®æŒä¹…åŒ–
# =========================================================================


class TestPersistence:
    """é‡å»º SQLiteCache å®ä¾‹åæ•°æ®ä»ç„¶å¯è¯»"""

    def test_cache_entries_persist(self, tmp_db):
        """é€šç”¨ç¼“å­˜è¡¨æ•°æ®æŒä¹…åŒ–"""

        async def _test():
            # å†™å…¥
            c1 = SQLiteCache(db_path=tmp_db)
            await c1.set("persist_key", {"data": [1, 2, 3]})

            # ç”¨å…¨æ–°å®ä¾‹è¯»å–
            c2 = SQLiteCache(db_path=tmp_db)
            result = await c2.get("persist_key")
            assert result == {"data": [1, 2, 3]}

        run_async(_test())

    def test_market_data_persist(self, tmp_db):
        """å¸‚åœºæ•°æ®ä¸“ç”¨è¡¨æŒä¹…åŒ–"""

        async def _test():
            md = make_market_data("AAPL", days=15)

            c1 = SQLiteCache(db_path=tmp_db)
            await c1.save_market_data("AAPL", "1d", md)

            c2 = SQLiteCache(db_path=tmp_db)
            retrieved = await c2.get_market_data("AAPL", "1d")
            assert retrieved is not None
            assert len(retrieved) == 15

        run_async(_test())

    def test_market_data_json_persist(self, tmp_db):
        """MarketData é€šè¿‡ cache_entries è¡¨ (JSON åºåˆ—åŒ–) çš„æŒä¹…åŒ–"""

        async def _test():
            md = make_market_data("GOOGL", days=20)

            c1 = SQLiteCache(db_path=tmp_db)
            await c1.set("alphavantage:GOOGL:1d:20250101:20250201", md)

            c2 = SQLiteCache(db_path=tmp_db)
            restored = await c2.get("alphavantage:GOOGL:1d:20250101:20250201")
            assert isinstance(restored, MarketData)
            assert restored.symbol == "GOOGL"
            assert len(restored) == 20

            # é€æ¡å¯¹æ¯”
            for orig, rest in zip(md.data, restored.data):
                assert orig.close == rest.close

        run_async(_test())

    def test_ttl_persists(self, tmp_db):
        """TTL ä¿¡æ¯æŒä¹…åŒ–åˆ°ç£ç›˜ï¼Œæ–°å®ä¾‹ä»èƒ½è¯†åˆ«è¿‡æœŸ"""

        async def _test():
            c1 = SQLiteCache(db_path=tmp_db)
            await c1.set("short_lived", "temp", ttl=timedelta(milliseconds=50))

            await asyncio.sleep(0.1)

            c2 = SQLiteCache(db_path=tmp_db)
            assert await c2.get("short_lived") is None

        run_async(_test())

    def test_db_file_created(self, tmp_db):
        """é¦–æ¬¡æ“ä½œåæ•°æ®åº“æ–‡ä»¶åº”è¢«åˆ›å»º"""

        async def _test():
            assert not Path(tmp_db).exists()
            c = SQLiteCache(db_path=tmp_db)
            await c.set("trigger_init", True)
            assert Path(tmp_db).exists()

        run_async(_test())


# =========================================================================
# 8. ç¼“å­˜å‘½ä¸­/æœªå‘½ä¸­æµç¨‹ï¼ˆç«¯åˆ°ç«¯é›†æˆï¼‰
# =========================================================================


class TestCacheIntegration:
    """æ¨¡æ‹Ÿå®Œæ•´çš„ DataProvider + SQLiteCache äº¤äº’"""

    def test_first_call_misses_cache(self, cache):
        """é¦–æ¬¡è°ƒç”¨åº”ç©¿é€ç¼“å­˜ï¼Œè°ƒç”¨è¿œç«¯ API"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=cache)
            start = datetime(2025, 1, 1)
            end = datetime(2025, 1, 31)

            data = await provider.get_historical_data("AAPL", start, end)
            assert provider.api_call_count == 1
            assert not data.is_empty

        run_async(_test())

    def test_second_call_hits_cache(self, cache):
        """ç¬¬äºŒæ¬¡ç›¸åŒè¯·æ±‚åº”å‘½ä¸­ç¼“å­˜ï¼Œä¸å†è°ƒç”¨è¿œç«¯ API"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=cache)
            start = datetime(2025, 1, 1)
            end = datetime(2025, 1, 31)

            data1 = await provider.get_historical_data("AAPL", start, end)
            data2 = await provider.get_historical_data("AAPL", start, end)

            assert provider.api_call_count == 1  # åªè°ƒäº†ä¸€æ¬¡è¿œç«¯
            assert len(data1) == len(data2)

        run_async(_test())

    def test_different_params_miss_cache(self, cache):
        """ä¸åŒå‚æ•°åº”å„è‡ªç‹¬ç«‹ç¼“å­˜"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=cache)

            await provider.get_historical_data("AAPL", datetime(2025, 1, 1), datetime(2025, 1, 31))
            await provider.get_historical_data("MSFT", datetime(2025, 1, 1), datetime(2025, 1, 31))
            await provider.get_historical_data("AAPL", datetime(2025, 2, 1), datetime(2025, 2, 28))

            # ä¸‰æ¬¡ä¸åŒå‚æ•° â†’ ä¸‰æ¬¡ API è°ƒç”¨
            assert provider.api_call_count == 3

        run_async(_test())

    def test_cached_data_content_matches(self, cache):
        """ç¼“å­˜è¿”å›çš„æ•°æ®ä¸é¦–æ¬¡ API è¿”å›çš„æ•°æ®å†…å®¹ä¸€è‡´"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=cache)
            start = datetime(2025, 1, 1)
            end = datetime(2025, 1, 31)

            data1 = await provider.get_historical_data("AAPL", start, end)
            data2 = await provider.get_historical_data("AAPL", start, end)

            assert data1.symbol == data2.symbol
            assert len(data1) == len(data2)
            for o1, o2 in zip(data1.data, data2.data):
                assert o1.timestamp == o2.timestamp
                assert o1.open == o2.open
                assert o1.close == o2.close

        run_async(_test())

    def test_no_cache_always_calls_api(self):
        """ä¸æ³¨å…¥ç¼“å­˜æ—¶æ¯æ¬¡éƒ½åº”è°ƒç”¨è¿œç«¯ API"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=None)
            start = datetime(2025, 1, 1)
            end = datetime(2025, 1, 31)

            await provider.get_historical_data("AAPL", start, end)
            await provider.get_historical_data("AAPL", start, end)

            assert provider.api_call_count == 2

        run_async(_test())


# =========================================================================
# 9. æ€§èƒ½å¯¹æ¯”
# =========================================================================


class TestPerformance:
    """ç¼“å­˜ vs è¿œç«¯æ•°æ®æºçš„å“åº”æ—¶é—´å¯¹æ¯”"""

    def test_cache_much_faster_than_remote(self, cache):
        """ä»ç¼“å­˜è¯»å–åº”æ˜¾è‘—å¿«äºï¼ˆæ¨¡æ‹Ÿçš„ï¼‰è¿œç«¯è°ƒç”¨"""

        async def _test():
            provider = FakeRemoteProvider(cache_backend=cache, latency=0.1)
            start = datetime(2025, 1, 1)
            end = datetime(2025, 1, 31)

            # é¦–æ¬¡ï¼šèµ°è¿œç«¯
            t0 = time.perf_counter()
            await provider.get_historical_data("AAPL", start, end)
            remote_time = time.perf_counter() - t0

            # ç¬¬äºŒæ¬¡ï¼šèµ°ç¼“å­˜
            t0 = time.perf_counter()
            await provider.get_historical_data("AAPL", start, end)
            cache_time = time.perf_counter() - t0

            # ç¼“å­˜åº”è‡³å°‘å¿« 5 å€
            assert cache_time < remote_time / 5, f"ç¼“å­˜ ({cache_time:.4f}s) æœªæ˜¾è‘—å¿«äºè¿œç«¯ ({remote_time:.4f}s)"

        run_async(_test())

    def test_batch_cache_performance(self, cache):
        """æ‰¹é‡ç¼“å­˜è¯»å–çš„ååé‡"""

        async def _test():
            # é¢„çƒ­ï¼šå†™å…¥ 100 æ¡
            for i in range(100):
                await cache.set(f"perf_{i}", {"index": i, "data": list(range(50))})

            # è¯»å–
            t0 = time.perf_counter()
            for i in range(100):
                result = await cache.get(f"perf_{i}")
                assert result is not None
            elapsed = time.perf_counter() - t0

            # 100 æ¬¡è¯»å–åº”åœ¨ 2 ç§’å†…å®Œæˆ
            assert elapsed < 2.0, f"100 æ¬¡ç¼“å­˜è¯»å–è€—æ—¶ {elapsed:.3f}sï¼Œè¶…è¿‡ 2 ç§’"

        run_async(_test())

    def test_market_data_cache_vs_serialize_overhead(self, cache):
        """å¤§é‡ MarketData ç¼“å­˜çš„åºåˆ—åŒ–/ååºåˆ—åŒ–å¼€é”€å¯æ¥å—"""

        async def _test():
            large_md = make_market_data("AAPL", days=365)

            # å†™å…¥
            t0 = time.perf_counter()
            await cache.set("large_md", large_md)
            write_time = time.perf_counter() - t0

            # è¯»å–
            t0 = time.perf_counter()
            restored = await cache.get("large_md")
            read_time = time.perf_counter() - t0

            assert len(restored) == 365
            # è¯»å†™å„åº”åœ¨ 1 ç§’å†…
            assert write_time < 1.0, f"å†™å…¥ 365 å¤©æ•°æ®è€—æ—¶ {write_time:.3f}s"
            assert read_time < 1.0, f"è¯»å– 365 å¤©æ•°æ®è€—æ—¶ {read_time:.3f}s"

        run_async(_test())


# =========================================================================
# 10. get_or_set ç¼“å­˜ç©¿é€ä¿æŠ¤
# =========================================================================


class TestGetOrSet:
    """get_or_set çš„è¡Œä¸ºéªŒè¯"""

    def test_get_or_set_miss_calls_factory(self, cache):
        """ç¼“å­˜æœªå‘½ä¸­æ—¶åº”è°ƒç”¨ factory å¹¶ç¼“å­˜ç»“æœ"""

        async def _test():
            call_count = 0

            def factory():
                nonlocal call_count
                call_count += 1
                return "generated_value"

            result = await cache.get_or_set("k", factory)
            assert result == "generated_value"
            assert call_count == 1

            # ç¬¬äºŒæ¬¡ä¸åº”å†è°ƒç”¨ factory
            result2 = await cache.get_or_set("k", factory)
            assert result2 == "generated_value"
            assert call_count == 1

        run_async(_test())

    def test_get_or_set_hit_skips_factory(self, cache):
        """ç¼“å­˜å‘½ä¸­æ—¶ä¸è°ƒç”¨ factory"""

        async def _test():
            await cache.set("k", "existing")

            called = False

            def factory():
                nonlocal called
                called = True
                return "new"

            result = await cache.get_or_set("k", factory)
            assert result == "existing"
            assert called is False

        run_async(_test())

    def test_get_or_set_async_factory(self, cache):
        """æ”¯æŒå¼‚æ­¥ factory å‡½æ•°"""

        async def _test():
            async def async_factory():
                return {"async": True}

            result = await cache.get_or_set("k", async_factory)
            assert result == {"async": True}

        run_async(_test())

    def test_get_or_set_with_ttl(self, cache):
        """get_or_set æ”¯æŒ TTL å‚æ•°"""

        async def _test():
            await cache.get_or_set("k", lambda: "temp", ttl=timedelta(milliseconds=50))
            assert await cache.get("k") == "temp"

            await asyncio.sleep(0.1)
            assert await cache.get("k") is None

        run_async(_test())

    def test_get_or_set_non_callable(self, cache):
        """factory ä¸ºé callable æ—¶ç›´æ¥ä½œä¸ºé»˜è®¤å€¼"""

        async def _test():
            result = await cache.get_or_set("k", "default_value")
            assert result == "default_value"

        run_async(_test())


# =========================================================================
# 11. ç»Ÿè®¡ä¿¡æ¯
# =========================================================================


class TestStats:
    """stats() è¿”å›çš„ç¼“å­˜ç»Ÿè®¡"""

    def test_empty_stats(self, cache):
        async def _test():
            stats = await cache.stats()
            assert stats["total_entries"] == 0
            assert stats["expired_entries"] == 0
            assert stats["market_data_entries"] == 0
            assert stats["unique_symbols"] == 0

        run_async(_test())

    def test_stats_after_inserts(self, cache):
        async def _test():
            await cache.set("a", 1)
            await cache.set("b", 2)

            md = make_market_data("AAPL", days=10)
            await cache.save_market_data("AAPL", "1d", md)

            stats = await cache.stats()
            assert stats["total_entries"] == 2
            assert stats["market_data_entries"] == 10
            assert stats["unique_symbols"] == 1

        run_async(_test())

    def test_stats_expired_count(self, cache):
        async def _test():
            await cache.set("exp1", 1, ttl=timedelta(milliseconds=50))
            await cache.set("exp2", 2, ttl=timedelta(milliseconds=50))
            await cache.set("perm", 3)

            await asyncio.sleep(0.1)

            stats = await cache.stats()
            assert stats["expired_entries"] == 2
            assert stats["total_entries"] == 3  # æœªæ¸…ç†å‰ä»è®¡å…¥æ€»æ•°

        run_async(_test())

    def test_stats_db_size(self, cache):
        async def _test():
            await cache.set("data", "x" * 1000)
            stats = await cache.stats()
            assert stats["db_size_bytes"] > 0
            assert stats["db_size_mb"] >= 0
            assert "db_path" in stats

        run_async(_test())


# =========================================================================
# 12. å¹¶å‘è®¿é—®
# =========================================================================


class TestConcurrency:
    """å¤šä¸ªåç¨‹åŒæ—¶æ“ä½œç¼“å­˜"""

    def test_concurrent_writes(self, cache):
        """å¹¶å‘å†™å…¥ä¸åº”ä¸¢æ•°æ®æˆ–æŠ›å¼‚å¸¸"""

        async def _test():
            async def writer(i):
                await cache.set(f"concurrent_{i}", i)

            await asyncio.gather(*[writer(i) for i in range(50)])

            # éªŒè¯æ‰€æœ‰æ•°æ®å‡å·²å†™å…¥
            for i in range(50):
                val = await cache.get(f"concurrent_{i}")
                assert val == i

        run_async(_test())

    def test_concurrent_read_write(self, cache):
        """è¯»å†™æ··åˆå¹¶å‘ä¸åº”å‡ºé”™"""

        async def _test():
            await cache.set("shared", "initial")

            results = []

            async def reader():
                val = await cache.get("shared")
                results.append(val)

            async def writer():
                await cache.set("shared", "updated")

            tasks = [reader() for _ in range(10)] + [writer() for _ in range(5)]
            await asyncio.gather(*tasks)

            # æœ€ç»ˆå€¼åº”ä¸º "updated"
            final = await cache.get("shared")
            assert final == "updated"

            # æ‰€æœ‰è¯»å–ç»“æœåº”ä¸º "initial" æˆ– "updated"
            for r in results:
                assert r in ("initial", "updated")

        run_async(_test())

    def test_concurrent_initialization(self, tmp_db):
        """å¤šä¸ª SQLiteCache å®ä¾‹å¹¶å‘åˆå§‹åŒ–åŒä¸€æ•°æ®åº“ä¸åº”æŠ¥é”™"""

        async def _test():
            caches = [SQLiteCache(db_path=tmp_db) for _ in range(5)]

            async def init_and_write(c, i):
                await c.set(f"init_{i}", i)

            await asyncio.gather(*[init_and_write(c, i) for i, c in enumerate(caches)])

            # ç”¨æ–°å®ä¾‹éªŒè¯
            verify = SQLiteCache(db_path=tmp_db)
            for i in range(5):
                assert await verify.get(f"init_{i}") == i

        run_async(_test())


# =========================================================================
# 13. ä¸Šä¸‹æ–‡ç®¡ç†å™¨
# =========================================================================


class TestContextManager:
    """async with ç”¨æ³•"""

    def test_async_context_manager(self, tmp_db):
        async def _test():
            async with SQLiteCache(db_path=tmp_db) as c:
                await c.set("ctx_key", "ctx_value")
                assert await c.get("ctx_key") == "ctx_value"

        run_async(_test())


# =========================================================================
# 14. è¾¹ç•Œä¸å¼‚å¸¸åœºæ™¯
# =========================================================================


class TestEdgeCases:
    """è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸å¤„ç†"""

    def test_very_long_key(self, cache):
        """è¶…é•¿ç¼“å­˜é”®"""

        async def _test():
            long_key = "k" * 10_000
            await cache.set(long_key, "value")
            assert await cache.get(long_key) == "value"

        run_async(_test())

    def test_empty_string_value(self, cache):
        """ç©ºå­—ç¬¦ä¸²ä½œä¸ºå€¼ï¼ˆä¸åº”è¢«è¯¯åˆ¤ä¸º Noneï¼‰"""

        async def _test():
            await cache.set("empty_str", "")
            result = await cache.get("empty_str")
            # pickle åºåˆ—åŒ–åç©ºå­—ç¬¦ä¸²æ˜¯åˆæ³•çš„å€¼
            assert result == ""

        run_async(_test())

    def test_none_value(self, cache):
        """None ä½œä¸ºå€¼"""

        async def _test():
            await cache.set("none_val", None)
            # å½“å‰å®ç°ä¸­ get è¿”å› None è¡¨ç¤ºä¸å­˜åœ¨ï¼Œ
            # æ‰€ä»¥å­˜ None å¯èƒ½ä¸"ä¸å­˜åœ¨"æ··æ·†ï¼Œè¿™æ˜¯ä¸€ä¸ªå·²çŸ¥è¡Œä¸º
            result = await cache.get("none_val")
            # æ— è®ºè¿”å› None è¿˜æ˜¯æœ‰å€¼ï¼Œä¸åº”æŠ›å¼‚å¸¸
            assert result is None

        run_async(_test())

    def test_large_market_data(self, cache):
        """å¤§é‡ OHLCV æ•°æ®ï¼ˆæ¨¡æ‹Ÿ 5 å¹´æ—¥çº¿ â‰ˆ 1260 æ¡ï¼‰"""

        async def _test():
            large_md = make_market_data("SPY", days=1260)
            await cache.set("spy_5y", large_md)

            restored = await cache.get("spy_5y")
            assert len(restored) == 1260
            assert restored.symbol == "SPY"

        run_async(_test())

    def test_special_characters_in_key(self, cache):
        """ç¼“å­˜é”®åŒ…å«ç‰¹æ®Šå­—ç¬¦"""

        async def _test():
            special_keys = [
                "alphavantage:600519.SHH:1d:20250101:20250201",
                "key with spaces",
                "key/with/slashes",
                "ä¸­æ–‡é”®å",
                "emoji_ğŸ”‘",
            ]
            for i, key in enumerate(special_keys):
                await cache.set(key, i)

            for i, key in enumerate(special_keys):
                assert await cache.get(key) == i

        run_async(_test())

    def test_repr(self, tmp_db):
        """__repr__ è¾“å‡ºåŒ…å«æ•°æ®åº“è·¯å¾„"""
        c = SQLiteCache(db_path=tmp_db)
        r = repr(c)
        assert "SQLiteCache" in r
        assert tmp_db in r

    def test_is_subclass_of_cache_backend(self, cache):
        """SQLiteCache æ˜¯ CacheBackend çš„å­ç±»"""
        assert isinstance(cache, CacheBackend)

    def test_db_directory_auto_created(self, tmp_path):
        """db_path çš„çˆ¶ç›®å½•ä¸å­˜åœ¨æ—¶åº”è‡ªåŠ¨åˆ›å»º"""
        nested = tmp_path / "a" / "b" / "c" / "cache.db"
        c = SQLiteCache(db_path=str(nested))
        assert nested.parent.exists()

    def test_clear_also_clears_market_data_table(self, cache):
        """clear() åº”åŒæ—¶æ¸…ç©º cache_entries å’Œ market_data ä¸¤å¼ è¡¨"""

        async def _test():
            await cache.set("generic", "value")
            md = make_market_data("AAPL", days=5)
            await cache.save_market_data("AAPL", "1d", md)

            await cache.clear()

            assert await cache.get("generic") is None
            assert await cache.get_market_data("AAPL", "1d") is None

        run_async(_test())
